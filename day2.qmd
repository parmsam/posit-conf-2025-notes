# Day 2: Conf Day 1

## 10 Years of Data Science Tools... and What Happens Next
- Thinking, then writing to thinking by writing 
- Nietzsche and the impact of his typewriter on his writing
- Tools aren't interchangeable
- Tools can shape our thinking
    - The tools you make and use matter alot
- Connect the people who make the tools directly with the people who use them
    - Cut out the unnecessary middleman
- Sampling bias
    - If you just listen to the loudest voices, you will get a biased sample
- Missing values
    - Users mostly don't know what they want
    - Sometimes you have to fill in the blanks
- Watch people use your tool. You will always be surprised.
    - People do things you didn't expect
- Make complicated things simple
- Take complexity away from the user and put it in the tool
- Meet people where they are
    - Even if it's not where you want them to be, meet them there first
    - People don't always follow best practices and shouldn't always be expected to
    - You need to compromise on enforcing reproducibility to make a tool more ergonomic
- Empowering your users 
    - Extensions and plugins
    - Shortcuts
- A tools output is shaped by it's design
    - The world we experience is shaped by the output of many tools
    - A tool is a statement of what you want the world to become


## Plumber2
- https://plumber2.posit.co/
- https://plumber2.posit.co/articles/routing-and-input.html?q=param#required-parameters
- Async built in using mirai
- Support for Shiny
- Support for Quarto

## Obsidian
- https://obsidian.md/
- https://stephango.com/

## Air
- https://posit-dev.github.io/air/cli.html

## Vitals
- https://vitals.tidyverse.org/
- https://github.com/simonpcouch/conf-25

## Shinyreact
- https://github.com/wch/shiny-react
- https://github.com/wch/create-shiny-react-app

## Shinystate
- https://github.com/rpodcast/shinystate/

## Otel
- https://otel.r-lib.org/index.html
    - https://opentelemetry.io/

## LLM open source packages and libraries
- https://ellmer.tidyverse.org/
- https://posit-dev.github.io/chatlas/

## Tool calling
- https://ellmer.tidyverse.org/articles/tool-calling.html#using-the-tool

## Posit AI's newsletter
- https://posit.co/blog/?post_tag=ai-newsletter

## Structured data extraction
- https://ellmer.tidyverse.org/articles/prompt-design.html#structured-data

## Querychat
- https://github.com/posit-dev/querychat

## Shinyrealtime
- https://github.com/posit-dev/shinyrealtime
- https://platform.openai.com/docs/api-reference/realtime

## ggbot2
- https://github.com/tidyverse/ggbot2

## Positron assistant
- https://positron.posit.co/assistant.html
- Assistant can explain or fix warnings/errors
- Currently require Anthropic API key
    - Will be via various providers such as Copilot, AWS Bedrock, LLM gateways, Databricks, Snowflake, etc
- Support for other models TBD
- "Lethal Trifecta" and "OWASP LLM Top 10"
- Lethal Trifecta: Three vulnerabilities that become extremely dangerous when combined together
    - https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/
    - Remote code execution + privilege escalation + lateral movement
    - SQL injection + weak authentication + data exposure
    - XSS + session flaws + poor authorization
    - The key idea: separate vulnerabilities become much worse when exploited together.
- OWASP LLM Top 10: Security framework for Large Language Model applications
    1. **Prompt Injection** - Manipulating AI inputs to override instructions
    2. **Insecure Output Handling** - Not validating AI outputs properly
    3. **Training Data Poisoning** - Corrupting the data used to train models
    4. **Model Denial of Service** - Overloading AI systems with expensive requests
    5. **Supply Chain Vulnerabilities** - Risks from third-party models/data
    6. **Sensitive Information Disclosure** - AI accidentally revealing private data
    7. **Insecure Plugin Design** - Vulnerable AI extensions/add-ons
    8. **Excessive Agency** - Giving AI too much autonomy/permissions
    9. **Overreliance** - Trusting AI outputs without sufficient oversight
    10. **Model Theft** - Stealing proprietary AI models

## Positron's databot
- https://positron.posit.co/databot.html
- WEAR Loop
    - Writing Python or R code
    - Executing code
    - Analyzing output of code
    - Repeats 3-5 times
    - Regrouping by suggesting next steps and wait for user input
- Repeat until satisfied or max iterations reached
- Extract insights into report (Quarto or Jupyter Notebook)
- https://posit.co/blog/introducing-databot/
- https://posit.co/blog/databot-is-not-a-flotation-device/
- Not a replacement for data scientists or analysts
